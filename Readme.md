NYC Taxi Data Science Project: Comprehensive ML Benchmarking

This repository presents a complete machine learning project focused on the New York City taxi trip dataset. The project is divided into two distinct machine learning challenges: Regression (predicting trip duration) and Classification (predicting the taxi vendor).

The entire pipeline covers data cleaning, feature engineering, implementation of various classical ML models, and deep learning architectures for benchmarking.

üìÇ Repository Structure

File/Folder

Purpose

Key Content

Data_prep.ipynb

Data Preparation & EDA

The starting point of the project, covering data cleaning, outlier handling, and feature engineering.

regression/

Part 1: Trip Duration Prediction (Regression Task)

Contains scripts for Linear Regression and Neural Networks.

classification/

Part 2: Vendor ID Classification (Classification Task)

Contains notebooks for classical and deep learning classification models.

1. Data Preparation & Feature Engineering

File: Data_prep.ipynb

This notebook details the crucial first steps of the pipeline:

Data Cleaning: Handling missing values and ensuring correct data types.

Outlier Removal: Filtering unrealistic data (e.g., zero-distance, extremely long/short duration trips, and geographical outliers).

Feature Engineering: Creating essential features like distance (Distance_KM), temporal features (day_of_week, time_of_day_category), and flags for subsequent modeling.

The resulting cleaned and featurized data is saved to be consumed by the model scripts.

2. Regression Analysis (Predicting Trip Duration)

The goal of this section is to predict the continuous variable trip_duration.

Models Implemented

File Name

Model Type

Description

linear_regre.py

Linear Regression

Implements a simple linear model as a baseline. Generates an HTML report.

all_nn_models.py

Neural Networks (Small, Medium, Large)

Combines the training and evaluation of three distinct Keras deep learning architectures to compare the impact of model complexity.

HTML_report_generator_all_nn.py

Reporting Utility

A helper script to generate detailed, visually appealing HTML reports for the Neural Network runs.

Regression Results

All regression model results are summarized in dedicated HTML reports:

regression/HTML_pages/nn_small_model.html

regression/HTML_pages/nn_medium_model.html

regression/HTML_pages/nn_larger_model.html

regression/linear_regression_report.html (Generated by linear_regre.py)

3. Classification Analysis (Predicting Vendor ID)

The goal of this section is to predict the categorical variable vendor_id (Vendor 1 or Vendor 2).

Models Implemented (Jupyter Notebooks)

The analysis compares performance across a wide range of classification algorithms:

Notebook

Model Type

DecisionTree.ipynb

Decision Tree Classifier

GBC.ipynb

Gradient Boosting Classifier

KNN.ipynb

K-Nearest Neighbors (KNN)

logistic-regression.ipynb

Logistic Regression

NN.ipynb

Neural Network Classifier

RandomForest.ipynb

Random Forest Classifier

SVM.ipynb

Support Vector Machine (SVM)

Classification Results & Visualizations

model_metrics.csv: A consolidated file containing the accuracy, F1-score, and log-loss for all implemented classification models on both training and test sets.

Visual Assets: PNG images illustrating key insights, such as feature importance plots for tree-based models and visualization of the decision boundaries.

‚öôÔ∏è Setup and Execution

Prerequisites

To run this project locally, you will need Python and the following key libraries:

pip install pandas numpy scikit-learn tensorflow matplotlib seaborn jupyter


Running the Pipeline

Start with Data Prep: Open and execute all cells in Data_prep.ipynb to ensure the cleaned data file is generated and saved in the expected location.

Run Regression Models: Execute the Python scripts in the regression/ folder:

python regression/linear_regre.py
python regression/all_nn_models.py


Run Classification Models: Open and run the individual Jupyter Notebooks in the classification/ folder to train the respective models, generate visualizations, and update the model_metrics.csv file.