# **NYC Taxi Data Science Project: Comprehensive ML Benchmarking**

This repository presents a complete machine learning project focused on the New York City taxi trip dataset. The project is divided into two distinct machine learning challenges: **Regression** (predicting trip duration) and **Classification** (predicting the taxi vendor).

The entire pipeline covers data cleaning, feature engineering, implementation of various classical ML models, and deep learning architectures for benchmarking.

## **üìÇ Repository Structure**

| File/Folder | Purpose | Key Content |
| :---- | :---- | :---- |
| **Data\_prep.ipynb** | **Data Preparation & EDA** | The starting point of the project, covering data cleaning, outlier handling, and feature engineering. |
| **regression/** | **Part 1: Trip Duration Prediction** (Regression Task) | Contains scripts for Linear Regression and Neural Networks. |
| **classification/** | **Part 2: Vendor ID Classification** (Classification Task) | Contains notebooks for classical and deep learning classification models. |

## **1\. Data Preparation & Feature Engineering**

**File:** Data\_prep.ipynb

This notebook details the crucial first steps of the pipeline:

* **Data Cleaning:** Handling missing values and ensuring correct data types.  
* **Outlier Removal:** Filtering unrealistic data (e.g., zero-distance, extremely long/short duration trips, and geographical outliers).  
* **Feature Engineering:** Creating essential features like distance (Distance\_KM), temporal features (day\_of\_week, time\_of\_day\_category), and flags for subsequent modeling.

The resulting cleaned and featurized data is saved to be consumed by the model scripts.

## **2\. Regression Analysis (Predicting Trip Duration)**

The goal of this section is to predict the continuous variable **trip\_duration**.

### **Models Implemented**

| File Name | Model Type | Description |
| :---- | :---- | :---- |
| linear\_regre.py | **Linear Regression** | Implements a simple linear model as a baseline. Generates an HTML report. |
| all\_nn\_models.py | **Neural Networks (Small, Medium, Large)** | Combines the training and evaluation of three distinct Keras deep learning architectures to compare the impact of model complexity. |
| HTML\_report\_generator\_all\_nn.py | **Reporting Utility** | A helper script to generate detailed, visually appealing HTML reports for the Neural Network runs. |

### **Regression Results**

All regression model results are summarized in dedicated HTML reports:

* regression/HTML\_pages/nn\_small\_model.html  
* regression/HTML\_pages/nn\_medium\_model.html  
* regression/HTML\_pages/nn\_larger\_model.html  
* regression/linear\_regression\_report.html (Generated by linear\_regre.py)

## **3\. Classification Analysis (Predicting Vendor ID)**

The goal of this section is to predict the categorical variable **vendor\_id** (Vendor 1 or Vendor 2).

### **Models Implemented (Jupyter Notebooks)**

The analysis compares performance across a wide range of classification algorithms:

| Notebook | Model Type |
| :---- | :---- |
| DecisionTree.ipynb | **Decision Tree Classifier** |
| GBC.ipynb | **Gradient Boosting Classifier** |
| KNN.ipynb | **K-Nearest Neighbors (KNN)** |
| logistic-regression.ipynb | **Logistic Regression** |
| NN.ipynb | **Neural Network Classifier** |
| RandomForest.ipynb | **Random Forest Classifier** |
| SVM.ipynb | **Support Vector Machine (SVM)** |

### **Classification Results & Visualizations**

* **model\_metrics.csv**: A consolidated file containing the accuracy, F1-score, and log-loss for all implemented classification models on both training and test sets.  
* **Visual Assets**: PNG images illustrating key insights, such as feature importance plots for tree-based models and visualization of the decision boundaries.

## **‚öôÔ∏è Setup and Execution**

### **Prerequisites**

To run this project locally, you will need Python and the following key libraries:

pip install pandas numpy scikit-learn tensorflow matplotlib seaborn jupyter

### **Running the Pipeline**

1. **Start with Data Prep:** Open and execute all cells in **Data\_prep.ipynb** to ensure the cleaned data file is generated and saved in the expected location.  
2. **Run Regression Models:** Execute the Python scripts in the regression/ folder:  
   python regression/linear\_regre.py  
   python regression/all\_nn\_models.py

3. **Run Classification Models:** Open and run the individual Jupyter Notebooks in the classification/ folder to train the respective models, generate visualizations, and update the model\_metrics.csv file.